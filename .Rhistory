r6 <- read_csv("./data/rainbow_6.csv")
import tidyverse
library(tidyverse)
r6 <- read_csv("./data/rainbow_6.csv")
View(r6)
library(tidyverse)
r6 <- read_csv("./data/rainbow_6.csv")
rocket_league <- read_csv("./data/rocket_league.csv")
r6 <- read_csv("./data/rainbow_6.csv")
rocket_league <- read_csv("./data/rocket_league.csv")
View(rocket_league)
View(rocket_league)
View(rocket_league)
View(r6)
r6_data <- r6 %>%
mutate(match_win = ifelse(winner == team_a, 1, 0),  # 1 if team_a won, 0 if team_b won
early_win_indicator = ifelse(early_rounds_won_a > early_rounds_won_b, 1, 0))
r6_data <- r6 %>%
mutate(match_win = ifelse(Winner == Team_A, 1, 0),  # 1 if team_a won, 0 if team_b won
early_win_indicator = ifelse(Early_Rounds_Won_A > Early_Rounds_Won_B, 1, 0))
View(r6_data)
library(tidyverse)
library(brms)
# imports -----------------------------------------------------------------
library(tidyverse)
library(dplyr)
# initialize --------------------------------------------------------------
r6 <- read_csv("./data/rainbow_6.csv")
rocket_league <- read_csv("./data/rocket_league.csv")
r6 <- r6 %>%
rename_all(tolower)
# wrangling ---------------------------------------------------------------
r6_data <- r6 %>%
mutate(match_win = ifelse(Winner == Team_A, 1, 0),  # 1 if team_a won, 0 if team_b won
early_win_indicator = ifelse(Early_Rounds_Won_A > Early_Rounds_Won_B, 1, 0))
View(r6_data)
View(r6)
# imports -----------------------------------------------------------------
library(tidyverse)
library(dplyr)
# initialize --------------------------------------------------------------
r6 <- read_csv("./data/rainbow_6.csv")
rocket_league <- read_csv("./data/rocket_league.csv")
r6 <- r6 %>%
rename_all(tolower)
# wrangling ---------------------------------------------------------------
r6_data <- r6 %>%
mutate(match_win = ifelse(winner == team_a, 1, 0),  # 1 if team_a won, 0 if team_b won
early_win_indicator = ifelse(early_rounds_won_A > early_rounds_won_b, 1, 0))
View(r6_data)
r6_data <- r6 %>%
mutate(match_win = ifelse(winner == team_a, 1, 0),  # 1 if team_a won, 0 if team_b won
early_win_indicator = ifelse(early_rounds_won_a > early_rounds_won_b, 1, 0))
View(r6_data)
SEED <- 14124869
# Define the weakly informative prior using student_t distribution
t_prior <- student_t(df = 7, location = 0, scale = 2.5)
library(tidyverse)
library(dplyr)
library(rstanarm)
library(caret)
trainIndex <- createDataPartition(r6_data$match_win, p = 0.8, list = FALSE)
train_data <- r6_data[trainIndex, ]
test_data <- r6_data[-trainIndex, ]
model <- train(match_win ~ early_win_indicator,
data = train_data,
method = "glm",  # Generalized Linear Model for logistic regression
family = "binomial",  # Logistic regression
trControl = trainControl(method = "cv", number = 10))  # 10-fold cross-validation
summary(model)
# Make predictions on the test set
predictions <- predict(model, newdata = test_data)
# Evaluate the model's performance using confusion matrix
conf_matrix <- confusionMatrix(predictions, test_data$match_win)
View(train_data)
ggplot(conf_matrix) + geom_bar(aes(x = Reference, fill = Prediction), position = "fill")
# Make predictions on the test set
predictions <- predict(model, newdata = test_data)
# Evaluate the model's performance using confusion matrix
conf_matrix <- confusionMatrix(predictions, test_data$match_win)
trainIndex <- createDataPartition(r6_data$match_win, p = 0.8, list = FALSE)
training <- test[test_split,]
test <- r6_data %>% mutate_if(is.character, as.factor)
glimpse(test)
trainIndex <- createDataPartition(r6_data$match_win, p = 0.8, list = FALSE)
training <- test[test_split,]
test <- r6_data %>% mutate_if(is.character, as.factor)
glimpse(test)
trainIndex <- createDataPartition(r6_data$match_win, p = 0.8, list = FALSE)
# One Hot Encode the data
test_dummy <- dummyVars(outcome ~ ., data = test, fullRank = TRUE)
test <- r6_data %>% mutate_if(is.character, as.factor)
glimpse(test)
trainIndex <- createDataPartition(r6_data$match_win, p = 0.8, list = FALSE)
# One Hot Encode the data
test_dummy <- dummyVars(match_win ~ ., data = test, fullRank = TRUE)
test <- predict(test_dummy, newdata = test)
test <- data.frame(test)
adopt_vals <- df %>%
select(match_win)
# Step 1: Prepare Data
test <- r6_data %>%
mutate_if(is.character, as.factor) # Convert character columns to factors
glimpse(test)
# Step 2: One Hot Encode the data
test_dummy <- dummyVars(match_win ~ ., data = test, fullRank = TRUE)
test_encoded <- predict(test_dummy, newdata = test)
test_encoded <- data.frame(test_encoded)
# Attach the outcome (match_win) to the encoded dataset
adopt_vals <- r6_data %>% select(match_win)
test_encoded <- cbind(test_encoded, adopt_vals) # Attach outcomes to dummy df
glimpse(test_encoded)
# Step 3: Split into training and test sets (80% train, 20% test)
test_split <- createDataPartition(test_encoded$match_win, p = 0.8, list = FALSE)
training <- test_encoded[test_split,]
features_train <- training[ , !(names(training) %in% c('match_win'))]
target_train <- training[ , 'match_win']
test_set <- test_encoded[-test_split,]
features_test <- test_set[ , !(names(test_set) %in% c('match_win'))]
target_test <- test_set[ , 'match_win']
target_test <- as.factor(target_test) # Ensure target is a factor
# Step 4: Train Random Forest Model
# We choose mtry=9 because the dataset has 27 columns after one-hot encoding
rf_train <- randomForest(match_win ~ ., data = training, mtry = 9)
library(tidyverse)
library(dplyr)
library(caret)
library(randomForest)
# initialize --------------------------------------------------------------
r6 <- read_csv("./data/rainbow_6.csv")
rocket_league <- read_csv("./data/rocket_league.csv")
r6 <- r6 %>%
rename_all(tolower)
# wrangling ---------------------------------------------------------------
r6_data <- r6 %>%
mutate(match_win = ifelse(winner == team_a, 1, 0),
early_win_indicator = ifelse(early_rounds_won_a > early_rounds_won_b, 1, 0))
# model -------------------------------------------------------------------
# Step 1: Prepare Data
test <- r6_data %>%
mutate_if(is.character, as.factor) # Convert character columns to factors
glimpse(test)
# Step 2: One Hot Encode the data
test_dummy <- dummyVars(match_win ~ ., data = test, fullRank = TRUE)
test_encoded <- predict(test_dummy, newdata = test)
test_encoded <- data.frame(test_encoded)
# Attach the outcome (match_win) to the encoded dataset
adopt_vals <- r6_data %>% select(match_win)
test_encoded <- cbind(test_encoded, adopt_vals) # Attach outcomes to dummy df
glimpse(test_encoded)
# Step 3: Split into training and test sets (80% train, 20% test)
test_split <- createDataPartition(test_encoded$match_win, p = 0.8, list = FALSE)
training <- test_encoded[test_split,]
features_train <- training[ , !(names(training) %in% c('match_win'))]
target_train <- training[ , 'match_win']
test_set <- test_encoded[-test_split,]
features_test <- test_set[ , !(names(test_set) %in% c('match_win'))]
target_test <- test_set[ , 'match_win']
target_test <- as.factor(target_test) # Ensure target is a factor
# Step 4: Train Random Forest Model
# We choose mtry=9 because the dataset has 27 columns after one-hot encoding
rf_train <- randomForest(match_win ~ ., data = training, mtry = 9)
rf_preds <- predict(rf_train, newdata = features_test)
rf_preds <- ifelse(rf_preds >= 0.5, 1, 0) # Convert to binary predictions
# Create predictions df for both models
predictions <- cbind(data.frame(target_test, rf_preds))
predictions$rf_preds <- factor(predictions$rf_preds)
# Step 5: Train Logistic Regression Model
# Preprocess (center, scale, and impute missing values)
preprocess_object <- preProcess(features_train,
method = c('center', 'scale', 'knnImpute'))
features_train <- predict(preprocess_object, newdata = features_train)
features_test <- predict(preprocess_object, newdata = features_test)
# Combine features and target for logistic regression
full_train <- cbind(features_train, target_train)
glimpse(full_train) # Check the data
full_train <- full_train %>% rename(match_win = target_train) # Rename target
log_train <- glm(match_win ~ ., family = 'binomial', data = full_train)
summary(log_train) # Check logistic regression summary
# Predict using logistic regression model
log_pred <- predict(log_train, newdata = features_test, type = 'response')
log_pred <- ifelse(log_pred >= 0.5, 1, 0) # Convert to binary predictions
predictions$log_pred <- factor(log_pred) # Add log predictions to the predictions df
# Step 6: Add error rates to predictions df
predictions$log_error <- ifelse(predictions$target_test != predictions$log_pred, 1, 0)
summary(r6_data)
# Fit the logistic regression model
log_model <- glm(match_win ~ early_win_indicator, family = "binomial", data = r6_data)
# Check the model summary
summary(log_model)
predictions <- predict(log_model, newdata = df, type = "response")
# imports -----------------------------------------------------------------
library(tidyverse)
library(dplyr)
library(caret)
library(randomForest)
set.seed(123)
r6 <- read_csv("./data/rainbow_6.csv")
rocket_league <- read_csv("./data/rocket_league.csv")
r6 <- r6 %>%
rename_all(tolower)
r6_data <- r6 %>%
mutate(match_win = ifelse(winner == team_a, 1, 0),
early_win_indicator = ifelse(early_rounds_won_a > early_rounds_won_b, 1, 0))
train_index <- createDataPartition(r6_data$match_win, p = 0.8, list = FALSE)
train_data <- df[train_index, ]
# Make predictions on the test data
predictions <- predict(log_model, newdata = test_data, type = "response")
predicted_class <- ifelse(predictions >= 0.5, 1, 0) # Convert to binary predictions
# Evaluate model performance with a confusion matrix
conf_matrix <- table(predicted_class, test_data$match_win)
print(conf_matrix)
library(tidyverse)
library(dplyr)
library(caret)
library(randomForest)
set.seed(1999)
# initialize --------------------------------------------------------------
r6 <- read_csv("./data/rainbow_6.csv")
rocket_league <- read_csv("./data/rocket_league.csv")
r6 <- r6 %>%
rename_all(tolower)
# wrangling ---------------------------------------------------------------
r6_data <- r6 %>%
mutate(match_win = ifelse(winner == team_a, 1, 0),
early_win_indicator = ifelse(early_rounds_won_a > early_rounds_won_b, 1, 0))
# train and test split ----------------------------------------------------
train_index <- createDataPartition(r6_data$match_win, p = 0.8, list = FALSE)
train_data <- df[train_index, ]
library(tidyverse)
library(dplyr)
library(caret)
library(randomForest)
set.seed(1999)
r6 <- read_csv("./data/rainbow_6.csv")
rocket_league <- read_csv("./data/rocket_league.csv")
r6 <- r6 %>%
rename_all(tolower)
r6_data <- r6 %>%
mutate(match_win = ifelse(winner == team_a, 1, 0),
early_win_indicator = ifelse(early_rounds_won_a > early_rounds_won_b, 1, 0))
train_index <- createDataPartition(r6_data$match_win, p = 0.8, list = FALSE)
train_data <- df[train_index, ]
# Fit the logistic regression model
log_model <- glm(match_win ~ early_win_indicator, family = "binomial", data = train_data)
# Check the model summary
summary(log_model)
# Make predictions on the test data
predictions <- predict(log_model, newdata = test_data, type = "response")
predicted_class <- ifelse(predictions >= 0.5, 1, 0) # Convert to binary predictions
# Evaluate model performance with a confusion matrix
conf_matrix <- table(predicted_class, test_data$match_win)
print(conf_matrix)
# Check the model summary
summary(log_model)
library(tidyverse)
library(dplyr)
library(caret)
library(randomForest)
library(ggplot2)
cm <- confusionMatrix(rf_preds, target_test)
ggplot(data.frame(predicted=log_pred, actual=target_test), aes(x=predicted, fill=factor(actual))) +
geom_density(alpha=0.5) +
labs(title="Predicted Probabilities vs Actual Outcome", x="Predicted Probability", y="Density") +
theme_minimal()
# Create a dataframe for plotting
plot_data <- data.frame(
Actual = factor(target_test, levels = c(0, 1)),
Predicted = factor(log_pred, levels = c(0, 1))
)
# Bar plot
ggplot(plot_data, aes(x=Actual, fill=Predicted)) +
geom_bar(position="dodge") +
labs(title="Predicted vs Actual Match Outcomes",
x="Actual Outcome", y="Count") +
scale_fill_manual(values=c("red", "blue"), labels=c("Loss", "Win")) +
theme_minimal()
ggplot(data.frame(Predicted_Prob = log_pred, Actual = target_test),
aes(x=Predicted_Prob, y=Actual)) +
geom_jitter(width=0.05, height=0.1, alpha=0.5, color="blue") +
geom_smooth(method="lm", se=FALSE, color="red") +
labs(title="Predicted Probability vs Actual Outcome",
x="Predicted Probability", y="Actual Outcome") +
theme_minimal()
predictions <- predict(log_model, newdata = test_data, type = "response")
print(conf_matrix)
library(tidyverse)
library(dplyr)
library(caret)
library(randomForest)
library(ggplot2)
set.seed(1999)
# initialize --------------------------------------------------------------
r6 <- read_csv("./data/rainbow_6.csv")
rocket_league <- read_csv("./data/rocket_league.csv")
r6 <- r6 %>%
rename_all(tolower)
# wrangling ---------------------------------------------------------------
r6_data <- r6 %>%
mutate(match_win = ifelse(winner == team_a, 1, 0),
early_win_indicator = ifelse(early_rounds_won_a > early_rounds_won_b, 1, 0))
# train and test split ----------------------------------------------------
train_index <- createDataPartition(r6_data$match_win, p = 0.8, list = FALSE)
train_data <- df[train_index, ]
library(tidyverse)
library(dplyr)
library(caret)
library(randomForest)
library(ggplot2)
set.seed(1999)
r6 <- read_csv("./data/rainbow_6.csv")
rocket_league <- read_csv("./data/rocket_league.csv")
r6 <- r6 %>%
rename_all(tolower)
r6_data <- r6 %>%
mutate(match_win = ifelse(winner == team_a, 1, 0),
early_win_indicator = ifelse(early_rounds_won_a > early_rounds_won_b, 1, 0))
train_index <- createDataPartition(r6_data$match_win, p = 0.8, list = FALSE)
train_data <- df[train_index, ]
# Fit the logistic regression model
log_model <- glm(match_win ~ early_win_indicator, family = "binomial", data = train_data)
predictions <- predict(log_model, newdata = test_data, type = "response")
# Fit the logistic regression model
log_model <- glm(match_win ~ early_win_indicator, family = "binomial", data = train_data)
train_index <- createDataPartition(r6_data$match_win, p = 0.8, list = FALSE)
train_data <- df[train_index, ]
library(tidyverse)
library(dplyr)
library(caret)
library(randomForest)
library(ggplot2)
set.seed(1999)
r6 <- read_csv("./data/rainbow_6.csv")
rocket_league <- read_csv("./data/rocket_league.csv")
r6 <- r6 %>%
rename_all(tolower)
r6_data <- r6 %>%
mutate(match_win = ifelse(winner == team_a, 1, 0),
early_win_indicator = ifelse(early_rounds_won_a > early_rounds_won_b, 1, 0))
train_index <- createDataPartition(r6_data$match_win, p = 0.8, list = FALSE)
train_data <- df[train_index, ]
test_data <- df[-train_index, ]
library(tidyverse)
library(dplyr)
library(caret)
library(randomForest)
library(ggplot2)
set.seed(1999)
r6 <- read_csv("./data/rainbow_6.csv")
r6 <- read_csv("./data/rainbow_6.csv")
rocket_league <- read_csv("./data/rocket_league.csv")
r6 <- r6 %>%
rename_all(tolower)
r6_data <- r6 %>%
mutate(match_win = ifelse(winner == team_a, 1, 0),
early_win_indicator = ifelse(early_rounds_won_a > early_rounds_won_b, 1, 0))
View(r6_data)
train_index <- createDataPartition(r6_data$match_win, p = 0.8, list = FALSE)
train_data <- df[train_index, ]
train_index <- createDataPartition(r6_data$match_win, p = 0.8, list = FALSE)
train_data <- r6_data[train_index, ]
test_data <- r6_data[-train_index, ]
# Fit the logistic regression model
log_model <- glm(match_win ~ early_win_indicator, family = "binomial", data = train_data)
View(train_index)
# Fit the logistic regression model
log_model <- glm(match_win ~ early_win_indicator, family = "binomial", data = train_data)
# Check the model summary
summary(log_model)
predictions <- predict(log_model, newdata = test_data, type = "response")
predicted_class <- ifelse(predictions >= 0.5, 1, 0)
# confusion matrix
conf_matrix <- table(predicted_class, test_data$match_win)
print(conf_matrix)
accuracy <- sum(diag(conf_matrix)) / sum(conf_matrix)
print(accuracy)
library(readr)
sheet_id <- "1JWk84PgKI_DNqgl8ncdx8_KJpBi7l7ZuoHrCutoBnGc"
url <- paste0("https://docs.google.com/spreadsheets/d/", sheet_id, "/gviz/tq?tqx=out:csv")
df <- read_csv(url) # Read data
sheet_id <- "1JWk84PgKI_DNqgl8ncdx8_KJpBi7l7ZuoHrCutoBnGc"
url <- paste0("https://docs.google.com/spreadsheets/d/", sheet_id, "/gviz/tq?tqx=out:csv")
df <- read_csv(url) # Read data
head(df) # Check data
View(df)
sheet_id <- "1JWk84PgKI_DNqgl8ncdx8_KJpBi7l7ZuoHrCutoBnGc"
gid <- "716521061"
url <- paste0("https://docs.google.com/spreadsheets/d/", sheet_id, "/export?format=csv&gid=", gid)
df <- read_csv(url) # Read data
head(df) # Check data
View(df)
library(tidyverse)
library(dplyr)
library(caret)
library(randomForest)
library(ggplot2)
library(readr)
set.seed(1999)
sheet_id <- "1JWk84PgKI_DNqgl8ncdx8_KJpBi7l7ZuoHrCutoBnGc"
gid <- "716521061"
url <- paste0("https://docs.google.com/spreadsheets/d/", sheet_id, "/export?format=csv&gid=", gid)
r6 <- read_csv(url)
r6 <- r6 %>%
rename_all(tolower)
View(r6)
r6_data <- r6 %>%
mutate(match_win = ifelse(winner == team_a, 1, 0),
early_win_indicator = ifelse(early_rounds_won_a > early_rounds_won_b, 1, 0))
View(r6_data)
View(r6_data)
train_index <- createDataPartition(r6_data$match_win, p = 0.8, list = FALSE)
train_data <- r6_data[train_index, ]
test_data <- r6_data[-train_index, ]
# Fit the logistic regression model
log_model <- glm(match_win ~ early_win_indicator, family = "binomial", data = train_data)
# Check the model summary
summary(log_model)
predictions <- predict(log_model, newdata = test_data, type = "response")
predicted_class <- ifelse(predictions >= 0.5, 1, 0)
# confusion matrix
conf_matrix <- table(predicted_class, test_data$match_win)
print(conf_matrix)
source("~/University of Arizona/Spring 2025/ISTA 498/esports_analysis/rocket_league_early_match_outcomes.R")
sheet_id <- "1JWk84PgKI_DNqgl8ncdx8_KJpBi7l7ZuoHrCutoBnGc"
gid <- "0"
url <- paste0("https://docs.google.com/spreadsheets/d/", sheet_id, "/export?format=csv&gid=", gid)
rocket_league <- read_csv(url)
rocket_league <- rocket_league %>%
rename_all(tolower)
library(tidyverse)
library(dplyr)
library(caret)
library(randomForest)
library(ggplot2)
library(readr)
set.seed(1999)
sheet_id <- "1JWk84PgKI_DNqgl8ncdx8_KJpBi7l7ZuoHrCutoBnGc"
gid <- "0"
url <- paste0("https://docs.google.com/spreadsheets/d/", sheet_id, "/export?format=csv&gid=", gid)
rocket_league <- read_csv(url)
rocket_league <- rocket_league %>%
rename_all(tolower)
View(rocket_league)
rocket_data <- rocket_league %>%
mutate(match_win = ifelse(winner == team_a, 1, 0),
early_win_indicator = ifelse(first_goal_a > first_goal_b, 1, 0))
View(rocket_league)
View(rocket_data)
train_index <- createDataPartition(rocket_data$match_win, p = 0.8, list = FALSE)
train_data <- rocket_data[train_index, ]
test_data <- rocket_data[-train_index, ]
# Fit the logistic regression model
log_model <- glm(match_win ~ early_win_indicator, family = "binomial", data = train_data)
# Check the model summary
summary(log_model)
predictions <- predict(log_model, newdata = test_data, type = "response")
predicted_class <- ifelse(predictions >= 0.5, 1, 0)
# confusion matrix
conf_matrix <- table(predicted_class, test_data$match_win)
print(conf_matrix)
